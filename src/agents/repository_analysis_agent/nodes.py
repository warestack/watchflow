from typing import Any

import httpx
import openai
import pydantic
import structlog
from langchain_core.messages import HumanMessage, SystemMessage

from src.agents.repository_analysis_agent.models import AnalysisState, PRSignal, RuleRecommendation
from src.agents.repository_analysis_agent.prompts import REPOSITORY_ANALYSIS_SYSTEM_PROMPT, RULE_GENERATION_USER_PROMPT
from src.integrations.github.api import github_client
from src.integrations.providers.factory import get_chat_model

logger = structlog.get_logger()


def _map_github_pr_to_signal(pr_data: dict[str, Any]) -> PRSignal:
    """
    Convert raw GitHub API PR response into a PRSignal Pydantic model.

    This helper implements the AI detection heuristic for the Immune System (Phase 6).
    It flags PRs as potentially AI-generated based on common LLM tool signatures in
    the description or title.

    Args:
        pr_data: Dictionary from GitHub API with keys: number, title, body,
                 author_association, lines_changed, has_issue_ref

    Returns:
        PRSignal model with all fields populated for hygiene analysis
    """
    # AI Detection Heuristic: Check for common LLM tool signatures
    body = (pr_data.get("body") or "").lower()
    title = (pr_data.get("title") or "").lower()

    ai_keywords = [
        "generated by claude",
        "cursor",
        "copilot",
        "chatgpt",
        "ai-generated",
        "llm",
        "i am an ai",
        "as an ai",
    ]

    is_ai_generated = any(keyword in body or keyword in title for keyword in ai_keywords)

    return PRSignal(
        pr_number=pr_data["number"],
        has_linked_issue=pr_data.get("has_issue_ref", False),
        author_association=pr_data.get("author_association", "NONE"),
        is_ai_generated_hint=is_ai_generated,
        lines_changed=pr_data.get("lines_changed", 0),
    )


async def fetch_repository_metadata(state: AnalysisState) -> AnalysisState:
    """
    Step 1: Gather raw signals from GitHub (Public or Private).
    This node populates the 'Shared Memory' (State) with facts about the repo.
    """
    repo = state.repo_full_name
    if not repo:
        raise ValueError("Repository full name is missing in state.")

    logger.info("repository_metadata_fetch_started", repo=repo)

    # 1. Fetch File Tree (Root)
    try:
        files = await github_client.list_directory_any_auth(repo_full_name=repo, path="")
    except httpx.HTTPStatusError as e:
        logger.error(
            "file_tree_fetch_failed",
            repo=repo,
            error=str(e),
            status_code=e.response.status_code,
            error_type="network_error",
        )
        files = []
    except Exception as e:
        logger.error("file_tree_fetch_failed", repo=repo, error=str(e), error_type="unknown_error")
        files = []

    file_names = [f["name"] for f in files] if files else []
    state.file_tree = file_names

    # 2. Heuristic Language Detection
    languages = []
    if "pom.xml" in file_names:
        languages.append("Java")
    if "package.json" in file_names:
        languages.append("JavaScript/TypeScript")
    if "requirements.txt" in file_names or "pyproject.toml" in file_names:
        languages.append("Python")
    if "go.mod" in file_names:
        languages.append("Go")
    if "Cargo.toml" in file_names:
        languages.append("Rust")
    state.detected_languages = languages

    # 3. Check for CI/CD presence
    state.has_ci = ".github" in file_names

    # 4. Fetch Documentation Snippets (for Context)
    readme_content = ""
    target_files = ["README.md", "readme.md", "CONTRIBUTING.md"]
    for target in target_files:
        if target in file_names:
            try:
                content = await github_client.get_file_content(
                    repo_full_name=repo, file_path=target, installation_id=None
                )
                if content:
                    readme_content = content[:2000]
                    break
            except httpx.HTTPStatusError:
                continue  # File not found is not a critical error
    state.readme_content = readme_content

    # 5. CODEOWNERS detection (root, .github/, docs/)
    codeowners_paths = ["CODEOWNERS", ".github/CODEOWNERS", "docs/CODEOWNERS"]
    has_codeowners = False
    for copath in codeowners_paths:
        try:
            co_content = await github_client.get_file_content(
                repo_full_name=repo, file_path=copath, installation_id=None
            )
            if co_content and len(co_content.strip()) > 0:
                has_codeowners = True
                break
        except httpx.HTTPStatusError:
            continue  # Not finding a CODEOWNERS file is expected
    state.has_codeowners = has_codeowners

    # 6. Analyze workflows for CI patterns
    workflow_patterns = []
    try:
        workflow_files = await github_client.list_directory_any_auth(repo_full_name=repo, path=".github/workflows")
        for wf in workflow_files:
            wf_name = wf["name"]
            if wf_name.endswith(".yml") or wf_name.endswith(".yaml"):
                try:
                    content = await github_client.get_file_content(
                        repo_full_name=repo, file_path=f".github/workflows/{wf_name}", installation_id=None
                    )
                    if content:
                        if "pytest" in content:
                            workflow_patterns.append("pytest")
                        if "actions/checkout" in content:
                            workflow_patterns.append("actions/checkout")
                        if "deploy" in content:
                            workflow_patterns.append("deploy")
                except httpx.HTTPStatusError:
                    continue  # A single broken workflow file shouldn't stop analysis
    except httpx.HTTPStatusError as e:
        logger.warning(
            "workflow_analysis_failed",
            repo=repo,
            error=str(e),
            status_code=e.response.status_code,
            error_type="network_error",
        )
    state.workflow_patterns = workflow_patterns

    logger.info(
        "repository_metadata_fetch_completed",
        repo=repo,
        file_count=len(file_names),
        detected_languages=languages,
        has_codeowners=has_codeowners,
        workflow_patterns=workflow_patterns,
    )

    return state


async def fetch_pr_signals(state: AnalysisState) -> AnalysisState:
    """
    Step 2: Fetch historical PR data for hygiene analysis (AI Immune System).

    This node acts as the "Sensory Input" for detecting AI spam patterns.
    It calculates HygieneMetrics from recent merged PRs to inform rule generation.
    """
    from src.agents.repository_analysis_agent.models import HygieneMetrics
    from src.integrations.github.client import GitHubClient

    repo = state.repo_full_name
    if not repo:
        raise ValueError("Repository full name is missing in state.")

    logger.info("pr_signals_fetch_started", repo=repo)

    # Extract owner and repo from full_name
    try:
        owner, repo_name = repo.split("/", 1)
    except ValueError as err:
        raise ValueError(f"Invalid repo format: {repo}. Expected 'owner/repo'.") from err

    # Initialize GraphQL-enabled client
    client = GitHubClient()

    try:
        # Fetch PR hygiene stats using GraphQL (avoids N+1 problem)
        pr_nodes = await client.fetch_pr_hygiene_stats(owner, repo_name)

        if not pr_nodes:
            # New repo or no PRs - set default metrics to avoid LLM crash
            logger.warning(
                "pr_signals_no_data", repo=repo, message="No merged PRs found. Using default hygiene metrics."
            )
            state.hygiene_summary = HygieneMetrics(
                unlinked_issue_rate=0.0,
                average_pr_size=0,
                first_time_contributor_count=0,
                issue_diff_mismatch_rate=0.0,
                ghost_contributor_rate=0.0,
                test_coverage_delta_avg=0.0,
                codeowner_bypass_rate=0.0,
                ai_generated_rate=0.0,
            )
            return state

        # Calculate metrics from GraphQL response
        total_prs = len(pr_nodes)

        # Calculate average_pr_size from changedFiles
        total_changed_files = sum(pr.get("changedFiles", 0) for pr in pr_nodes)
        average_pr_size = total_changed_files / total_prs if total_prs > 0 else 0.0

        # Calculate unlinked_issue_rate from closingIssuesReferences
        unlinked_count = sum(1 for pr in pr_nodes if pr.get("closingIssuesReferences", {}).get("totalCount", 0) == 0)
        unlinked_issue_rate = unlinked_count / total_prs if total_prs > 0 else 0.0

        # Calculate engagement_rate (proxy for ghost contributor) from comments
        total_comments = sum(pr.get("comments", {}).get("totalCount", 0) for pr in pr_nodes)
        engagement_rate = total_comments / total_prs if total_prs > 0 else 0.0

        # Legacy AI detection heuristic for demonstration
        ai_generated_count = 0
        for pr in pr_nodes:
            body = (pr.get("body") or "").lower()
            title = (pr.get("title") or "").lower()
            ai_keywords = [
                "generated by claude",
                "cursor",
                "copilot",
                "chatgpt",
                "ai-generated",
                "llm",
                "i am an ai",
                "as an ai",
            ]
            if any(keyword in body or keyword in title for keyword in ai_keywords):
                ai_generated_count += 1
        ai_generated_rate = ai_generated_count / total_prs if total_prs > 0 else 0.0

        # Calculate issue_diff_mismatch_rate
        issue_diff_mismatch_count = 0
        for pr in pr_nodes:
            issue_title = ""
            if pr.get("closingIssuesReferences", {}).get("nodes"):
                issue_title = pr["closingIssuesReferences"]["nodes"][0].get("title", "").lower()

            if issue_title:
                changed_files = [edge["node"]["path"] for edge in pr.get("files", {}).get("edges", [])]

                # Simple heuristic: check if any part of a changed file's path is in the issue title
                mismatch = True
                for file_path in changed_files:
                    path_parts = file_path.split("/")
                    if any(part in issue_title for part in path_parts if len(part) > 3):
                        mismatch = False
                        break
                if mismatch:
                    issue_diff_mismatch_count += 1

        issue_diff_mismatch_rate = issue_diff_mismatch_count / total_prs if total_prs > 0 else 0.0

        # Calculate codeowner_bypass_rate
        codeowner_bypass_count = 0
        for pr in pr_nodes:
            reviews = pr.get("reviews", {}).get("nodes", [])
            author = pr.get("author", {}).get("login")

            # This is a simplified check. A real implementation would parse CODEOWNERS.
            # For the demo, we assume any review from someone other than the author is sufficient.
            approved = any(review["state"] == "APPROVED" and review["author"]["login"] != author for review in reviews)

            if not approved:
                # Simplified: if no approved review from another user, it might be a bypass.
                # This doesn't actually check against CODEOWNERS file content.
                codeowner_bypass_count += 1

        codeowner_bypass_rate = codeowner_bypass_count / total_prs if total_prs > 0 else 0.0

        # Calculate new_code_test_coverage
        total_functions_added = 0
        total_test_functions_added = 0
        for pr in pr_nodes:
            diff_content = pr.get("diff_content", "")
            if diff_content:
                lines = diff_content.split("\n")
                for line in lines:
                    if line.startswith("+") and not line.startswith("+++") and "def " in line:
                        # Simple heuristic for Python: count new function definitions
                        file_path_info = next((ln for ln in lines if ln.startswith("+++ b/")), None)
                        if file_path_info:
                            if "test" in file_path_info:
                                total_test_functions_added += 1
                            else:
                                total_functions_added += 1

        new_code_test_coverage = 0.0
        if total_functions_added > 0:
            new_code_test_coverage = total_test_functions_added / total_functions_added

        state.hygiene_summary = HygieneMetrics(
            unlinked_issue_rate=unlinked_issue_rate,
            average_pr_size=int(average_pr_size),
            first_time_contributor_count=0,  # Not available in GraphQL response
            issue_diff_mismatch_rate=issue_diff_mismatch_rate,
            ghost_contributor_rate=1.0 - min(engagement_rate / 5.0, 1.0),  # Inverse of engagement (normalized)
            new_code_test_coverage=new_code_test_coverage,
            codeowner_bypass_rate=codeowner_bypass_rate,
            ai_generated_rate=ai_generated_rate,
        )

        # Convert for legacy PRSignal compatibility
        pr_signals = []
        for pr in pr_nodes:
            pr_signals.append(
                PRSignal(
                    pr_number=pr.get("number", 0),
                    has_linked_issue=pr.get("closingIssuesReferences", {}).get("totalCount", 0) > 0,
                    author_association="UNKNOWN",  # Not available in GraphQL query
                    is_ai_generated_hint=any(
                        keyword in (pr.get("body") or "").lower() + (pr.get("title") or "").lower()
                        for keyword in ["generated by claude", "cursor", "copilot", "chatgpt", "ai-generated", "llm"]
                    ),
                    lines_changed=pr.get("changedFiles", 0),
                )
            )
        state.pr_signals = pr_signals

        logger.info(
            "pr_signals_fetch_completed",
            repo=repo,
            total_prs=total_prs,
            unlinked_rate=f"{unlinked_issue_rate:.2%}",
            avg_size=int(average_pr_size),
            engagement_rate=f"{engagement_rate:.2f}",
            ai_rate=f"{ai_generated_rate:.2%}",
        )

        return state

    except Exception as e:
        logger.warning(
            "pr_signals_graphql_fallback",
            repo=repo,
            error=str(e),
            message="GraphQL failed, using safe defaults",
        )
        # Set defaults on error - DO NOT crash the node
        state.hygiene_summary = HygieneMetrics(
            unlinked_issue_rate=0.0,
            average_pr_size=0,
            first_time_contributor_count=0,
            issue_diff_mismatch_rate=0.0,
            ghost_contributor_rate=0.0,
            test_coverage_delta_avg=0.0,
            codeowner_bypass_rate=0.0,
            ai_generated_rate=0.0,
        )
        return state


async def generate_rule_recommendations(state: AnalysisState) -> AnalysisState:
    """
    Step 3: Send gathered signals to LLM to generate governance rules with AI Immune System reasoning.
    """
    repo_name = state.repo_full_name or "unknown/repo"
    logger.info("rule_generation_started", repo=repo_name, agent="repo_analysis")

    languages = state.detected_languages
    has_ci = state.has_ci
    has_codeowners = state.has_codeowners
    file_tree = state.file_tree
    readme_content = state.readme_content or ""
    workflow_patterns = state.workflow_patterns
    hygiene_summary = state.hygiene_summary

    # Format hygiene summary for LLM
    if hygiene_summary:
        hygiene_text = f"""- Unlinked Issue Rate: {hygiene_summary.unlinked_issue_rate:.1%} ({int(hygiene_summary.unlinked_issue_rate * 100)}% of PRs lack issue references)
- Average PR Size: {hygiene_summary.average_pr_size} lines changed
- First-Time Contributors: {hygiene_summary.first_time_contributor_count} in last 30 PRs"""
    else:
        hygiene_text = "- No PR history available (new repository or no merged PRs)"

    # 1. Construct Prompt with all available signals
    user_prompt = RULE_GENERATION_USER_PROMPT.format(
        repo_name=repo_name,
        languages=", ".join(languages) if languages else "Unknown",
        has_ci=str(has_ci),
        has_codeowners=str(has_codeowners),
        file_count=len(file_tree),
        workflow_patterns=", ".join(workflow_patterns) if workflow_patterns else "None detected",
        hygiene_summary=hygiene_text,
        file_tree_snippet="\n".join(file_tree[:25]),
        docs_snippet=readme_content[:1000],
    )

    # 2. Initialize LLM with temperature tuning for reasoning
    try:
        llm = get_chat_model(agent="repository_analysis", temperature=0.4)

        class RecommendationsList(pydantic.BaseModel):
            recommendations: list[RuleRecommendation]

        structured_llm = llm.with_structured_output(RecommendationsList)

        response = await structured_llm.ainvoke(
            [SystemMessage(content=REPOSITORY_ANALYSIS_SYSTEM_PROMPT), HumanMessage(content=user_prompt)]
        )

        valid_recs = response.recommendations
        logger.info("rule_generation_succeeded", repo=repo_name, recommendation_count=len(valid_recs))
        state.recommendations = valid_recs
        return state

    except openai.OpenAIError as e:
        logger.error("rule_generation_failed", repo=repo_name, error=str(e), error_type="llm_provider_error")
        fallback_reason = f"AI provider error: {e.__class__.__name__}"
    except pydantic.ValidationError as e:
        logger.error("rule_generation_failed", repo=repo_name, error=str(e), error_type="schema_mismatch")
        fallback_reason = "AI model returned data in an unexpected format."
    except Exception as e:
        logger.error("rule_generation_failed", repo=repo_name, error=str(e), error_type="unknown_error", exc_info=True)
        fallback_reason = f"An unexpected error occurred: {str(e)}"

    # Fallback for any of the caught exceptions
    fallback_rule = RuleRecommendation(
        key="manual_review_required",
        name="Manual Governance Review",
        description="AI analysis could not complete. Please review repository manually.",
        severity="low",
        category="system",
        reasoning=fallback_reason,
    )
    state.recommendations = [fallback_rule]
    state.error = fallback_reason
    return state
