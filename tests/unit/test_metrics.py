from src.agents.repository_analysis_agent.metrics import calculate_hygiene_metrics
from src.integrations.github.models import (
    Actor,
    CommentConnection,
    CommitConnection,
    FileConnection,
    FileEdge,
    FileNode,
    IssueConnection,
    IssueNode,
    PullRequest,
    ReviewConnection,
    ReviewNode,
)


# Helpers to create mock objects easily
def make_mock_pr(
    number: int = 1,
    title: str = "Test PR",
    body: str = "Description",
    changed_files: int = 1,
    additions: int = 10,
    deletions: int = 5,
    author_login: str = "author_user",
    linked_issues: list[str] | None = None,  # list of titles
    reviewers: list[tuple[str, str]] | None = None,  # list of (login, state)
    comment_count: int = 2,
    file_paths: list[str] | None = None,
    commit_messages: list[str] | None = None,
) -> PullRequest:
    issues = IssueConnection(nodes=[])
    if linked_issues:
        issues.nodes = [IssueNode(title=t, url="http://url") for t in linked_issues]

    reviews = ReviewConnection(nodes=[])
    if reviewers:
        reviews.nodes = [ReviewNode(author=Actor(login=login), state=state) for login, state in reviewers]

    files = FileConnection(edges=[])
    if file_paths:
        files.edges = [FileEdge(node=FileNode(path=p)) for p in file_paths]

    commit_nodes = []
    if commit_messages:
        from src.integrations.github.models import CommitMessage, CommitNode

        commit_nodes = [CommitNode(commit=CommitMessage(message=msg)) for msg in commit_messages]

    return PullRequest(
        number=number,
        title=title,
        body=body,
        changedFiles=changed_files,
        additions=additions,
        deletions=deletions,
        author=Actor(login=author_login),
        comments=CommentConnection(totalCount=comment_count),
        closingIssuesReferences=issues,
        reviews=reviews,
        commits=CommitConnection(nodes=commit_nodes),
        files=files,
    )


def test_empty_input():
    metrics = calculate_hygiene_metrics([])
    assert metrics.unlinked_issue_rate == 0.0
    assert metrics.average_pr_size == 0


def test_unlinked_issue_rate():
    # TEST CASE A: 10 PRs, 3 have no linked issues. Assert 0.3.
    prs = []
    # 7 with issues
    for _ in range(7):
        prs.append(make_mock_pr(linked_issues=["Fixes #123"]))
    # 3 without issues
    for _ in range(3):
        prs.append(make_mock_pr(linked_issues=[]))

    metrics = calculate_hygiene_metrics(prs)
    assert metrics.unlinked_issue_rate == 0.3


def test_average_pr_size():
    # TEST CASE B: Mock PR with 5000 lines changed (addition+deletion).
    # PR 1: 5000 additions, 0 deletions
    # PR 2: 10 additions, 10 deletions
    pr1 = make_mock_pr(additions=5000, deletions=0)
    pr2 = make_mock_pr(additions=10, deletions=10)

    metrics = calculate_hygiene_metrics([pr1, pr2])
    # Total lines = 5000 + 20 = 5020. Average = 2510.
    assert metrics.average_pr_size == 2510


def test_ghost_contributor_rate():
    # TEST CASE C: Identify PRs where author has 0 comments
    # PR 1: Author has 0 comments, Reviewers exist. -> Ghost
    pr1 = make_mock_pr(comment_count=0, reviewers=[("reviewer1", "COMMENTED")])
    # PR 2: Author has 2 comments -> Active
    pr2 = make_mock_pr(comment_count=2, reviewers=[("reviewer1", "COMMENTED")])

    metrics = calculate_hygiene_metrics([pr1, pr2])
    assert metrics.ghost_contributor_rate == 0.5


def test_issue_diff_mismatch_rate():
    # PR 1: Issue "Fix login bug", File "src/auth/login.py" -> Match
    pr1 = make_mock_pr(linked_issues=["Fix login bug"], file_paths=["src/auth/login.py"])

    # PR 2: Issue "Update Readme", File "backend/server.py" -> Mismatch
    pr2 = make_mock_pr(linked_issues=["Update Readme"], file_paths=["backend/server.py"])

    metrics = calculate_hygiene_metrics([pr1, pr2])
    assert metrics.issue_diff_mismatch_rate == 0.5


def test_codeowner_bypass_rate():
    # PR 1: Approved by other
    pr1 = make_mock_pr(author_login="dev1", reviewers=[("dev2", "APPROVED")])
    # PR 2: Approved by SELF (bypass) -> assuming simple logic (should be caught if reviewer == author)
    # Our logic: APPROVED and reviewer != author.
    # If reviewer IS author, it's not a valid approval in our loop, so it counts as bypass.
    pr2 = make_mock_pr(author_login="dev1", reviewers=[("dev1", "APPROVED")])
    # PR 3: Not approved
    pr3 = make_mock_pr(author_login="dev1", reviewers=[("dev2", "CHANGES_REQUESTED")])

    metrics = calculate_hygiene_metrics([pr1, pr2, pr3])
    # Only PR1 is valid. PR2 and PR3 are bypasses/unapproved.
    # Rate = 2/3 = 0.666 -> 0.67
    assert metrics.codeowner_bypass_rate == 0.67


def test_ai_generated_rate():
    pr1 = make_mock_pr(body="This was generated by Claude.")
    pr2 = make_mock_pr(body="Handwritten code.")

    metrics = calculate_hygiene_metrics([pr1, pr2])
    assert metrics.ai_generated_rate == 0.5


def test_ci_skip_rate():
    # PR 1: "[skip ci] update docs" -> Skip
    pr1 = make_mock_pr(commit_messages=["[skip ci] update docs"])
    # PR 2: "feat: new feature" -> No skip
    pr2 = make_mock_pr(commit_messages=["feat: new feature"])

    metrics = calculate_hygiene_metrics([pr1, pr2])
    assert metrics.ci_skip_rate == 0.5
